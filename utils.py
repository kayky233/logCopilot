import json
import os
import shutil

import pandas as pd
import streamlit as st

# ==========================================
# 0. ä¾èµ–åº“æ‡’åŠ è½½ (é˜²æ­¢æœªå®‰è£…åº“å¯¼è‡´é—ªé€€)
# ==========================================
try:
    import docx
except ImportError:
    docx = None

try:
    from pypdf import PdfReader
except ImportError:
    PdfReader = None

# ==========================================
# 1. å…¨å±€é…ç½®
# ==========================================
BASE_DIR = "analysis_workspace"
LOG_DIR = os.path.join(BASE_DIR, "logs")
MANUAL_ROOT_DIR = os.path.join(BASE_DIR, "manuals")
PROMPT_DIR = "prompts"
CONFIG_DIR = "user_configs"

# æ–°å¢ï¼šä»£ç åº“ä¸è·¯å¾„æ˜ å°„é…ç½®
CODEBASE_CONFIG_PATH = os.path.join(CONFIG_DIR, "codebase_path.txt")
PATH_MAP_CONFIG_PATH = os.path.join(CONFIG_DIR, "path_mapping.txt")

# é¢†åŸŸå®šä¹‰
DOMAINS = ["BSP", "CLK", "SWITCH", "OTHER"]

# ==========================================
# 2. åˆå§‹èµ„äº§ (Prompt é»˜è®¤å€¼)
# ==========================================
INIT_SYSTEM_PROMPTS = {
    "BSP": """# Role
ä½ æ˜¯ä¸€ä¸ªåŸºç«™ BSP (Board Support Package) ç³»ç»Ÿçš„æ•…éšœåˆ¤å†³ä¸“å®¶ã€‚

# Context
è´Ÿè´£åˆ†æå¯åŠ¨æµç¨‹ã€é©±åŠ¨åŠ è½½ã€å†…å­˜ç®¡ç†åŠç¡¬ä»¶æŠ½è±¡å±‚æ•…éšœã€‚
çº¦æŸï¼š
1. ä¸¥æ ¼ä¾æ®æ‰‹å†Œåˆ¤æ®ï¼Œç¦æ­¢å‘æ•£ã€‚
2. åŒºåˆ†å¯åŠ¨é˜¶æ®µçš„ç¬æ€æŠ¥é”™ä¸æ°¸ä¹…å¤±è´¥ã€‚
3. è¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚""",
    "CLK": """# Role
ä½ æ˜¯ä¸€ä¸ªåŸºç«™æ—¶é’Ÿä¸åŒæ­¥å­ç³»ç»Ÿ (CLK) çš„æ•…éšœåˆ¤å†³ä¸“å®¶ã€‚

# Context
è´Ÿè´£ GNSSã€1588v2ã€PLL çŠ¶æ€åŠæ—¶é’Ÿæºåˆ‡æ¢åˆ†æã€‚
çº¦æŸï¼š
1. é‡ç‚¹å…³æ³¨ Lock/Unlock çŠ¶æ€åˆ‡æ¢åŠæ—¶åºã€‚
2. åŒºåˆ†éšæ€§æ•…éšœï¼ˆç›¸ä½åå·®ï¼‰ä¸æ˜¾æ€§æ•…éšœï¼ˆå‘Šè­¦ï¼‰ã€‚
3. è¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚""",
    "SWITCH": """# Role
ä½ æ˜¯ä¸€ä¸ªåŸºç«™äº¤æ¢ä¸ç½‘ç»œå­ç³»ç»Ÿ (SWITCH) çš„æ•…éšœåˆ¤å†³ä¸“å®¶ã€‚

# Context
è´Ÿè´£ VLANã€ç«¯å£çŠ¶æ€ã€é£æš´æŠ‘åˆ¶åŠæŠ¥æ–‡è½¬å‘åˆ†æã€‚
çº¦æŸï¼š
1. åŒºåˆ†ç‰©ç†é“¾è·¯æŠ–åŠ¨ä¸é€»è¾‘é…ç½®é”™è¯¯ã€‚
2. è¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚""",
    "OTHER": """# Role
ä½ æ˜¯ä¸€ä¸ªé€šç”¨çš„è‡ªåŠ¨åŒ–æ•…éšœåˆ¤å†³ä¸“å®¶ã€‚

è¯·ä¸¥æ ¼æ ¹æ®å‚è€ƒæ‰‹å†Œåˆ¤æ–­æ—¥å¿—ä¸­æ˜¯å¦å­˜åœ¨æ•…éšœã€‚è¾“å‡º JSON æ ¼å¼ã€‚""",
}

INIT_TASK_TEMPLATE = """# Task
è¯·åˆ†æä»¥ä¸‹æ—¥å¿—æ˜¯å¦æ»¡è¶³æ•…éšœæ‰‹å†Œä¸­çš„å®šä¹‰ã€‚

## Input Data
ã€å‚è€ƒæ‰‹å†Œã€‘:
{manual_content}

ã€ç³»ç»Ÿæ—¥å¿—ã€‘:
{log_content}

## Output Format (JSON Only)
{
    "is_fault": true,
    "confidence": 95,
    "title": "æ•…éšœåç§° (From Manual)",
    "reason": "ç®€è¦è¯æ®é“¾...",
    "fix": "ä¿®å¤å»ºè®®..."
}"""

# ==========================================
# 3. åˆå§‹åŒ–ä¸ç¯å¢ƒæ„å»º
# ==========================================
def init_environment():
    """åˆå§‹åŒ–ç›®å½•å¹¶ç”Ÿæˆé»˜è®¤ Prompt æ–‡ä»¶"""
    for d in [BASE_DIR, LOG_DIR, PROMPT_DIR, MANUAL_ROOT_DIR, CONFIG_DIR]:
        if not os.path.exists(d):
            os.makedirs(d)

    # åˆå§‹åŒ–é¢†åŸŸç›®å½• & System Prompts
    for domain in DOMAINS:
        # 1. æ‰‹å†Œç›®å½•
        d_path = os.path.join(MANUAL_ROOT_DIR, domain)
        if not os.path.exists(d_path):
            os.makedirs(d_path)

        # 2. System Prompt æ–‡ä»¶
        sys_path = os.path.join(PROMPT_DIR, f"system_{domain}.md")
        if not os.path.exists(sys_path):
            with open(sys_path, "w", encoding="utf-8") as f:
                f.write(INIT_SYSTEM_PROMPTS.get(domain, INIT_SYSTEM_PROMPTS["OTHER"]))

    # ç”Ÿæˆé»˜è®¤ Task Template
    task_path = os.path.join(PROMPT_DIR, "task_default.md")
    if not os.path.exists(task_path):
        with open(task_path, "w", encoding="utf-8") as f:
            f.write(INIT_TASK_TEMPLATE)


def clear_workspace():
    """æ¸…ç©ºå·¥ä½œæ•°æ® (ä¿ç•™é…ç½®å’ŒPrompt)"""
    if os.path.exists(BASE_DIR):
        shutil.rmtree(BASE_DIR)
    init_environment()

# ==========================================
# 4. Prompt ç®¡ç†æ¥å£
# ==========================================
def get_prompt_path(layer, name):
    if layer == "SYSTEM":
        return os.path.join(PROMPT_DIR, f"system_{name}.md")
    if layer == "TASK":
        return os.path.join(PROMPT_DIR, f"task_{name}.md")
    return None


def load_prompt(layer, name):
    """è¯»å– Promptï¼Œä¼˜å…ˆè¯»æ–‡ä»¶"""
    path = get_prompt_path(layer, name)
    if path and os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            pass

    # Fallback
    if layer == "SYSTEM":
        return INIT_SYSTEM_PROMPTS.get(name, INIT_SYSTEM_PROMPTS["OTHER"])
    return INIT_TASK_TEMPLATE


def save_prompt(layer, name, content):
    path = get_prompt_path(layer, name)
    if path:
        try:
            with open(path, "w", encoding="utf-8") as f:
                f.write(content)
            return True
        except Exception:
            pass
    return False

# ==========================================
# 5. ç”¨æˆ·é…ç½®ç®¡ç†
# ==========================================
def get_config_path(user_id):
    safe_id = "".join([c for c in user_id if c.isalnum() or c in "_-"]) or "default"
    return os.path.join(CONFIG_DIR, f"config_{safe_id}.json")


def load_user_config(user_id):
    path = get_config_path(user_id)
    default = {
        "base_url": "http://api.openai.rnd.huawei.com/v1",
        "model_name": "gpt-oss-120b",
        "api_key": "sk-dummy",
    }
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return {**default, **json.load(f)}
        except Exception:
            pass
    return default


def save_user_config(user_id, config_data):
    try:
        with open(get_config_path(user_id), "w", encoding="utf-8") as f:
            json.dump(config_data, f, indent=4)
        return True
    except Exception:
        return False

# ==========================================
# 6. æœ¬åœ°ä»£ç åº“ä¸è·¯å¾„æ˜ å°„é…ç½®
# ==========================================
def load_codebase_root():
    """åŠ è½½ä»£ç åº“æ ¹è·¯å¾„"""
    if os.path.exists(CODEBASE_CONFIG_PATH):
        with open(CODEBASE_CONFIG_PATH, "r", encoding="utf-8") as f:
            return f.read().strip()
    return ""


def save_codebase_root(path):
    """ä¿å­˜ä»£ç åº“æ ¹è·¯å¾„"""
    try:
        with open(CODEBASE_CONFIG_PATH, "w", encoding="utf-8") as f:
            f.write(path.strip())
        return True, "å·²ä¿å­˜"
    except Exception as e:
        return False, str(e)


def load_path_prefix():
    """åŠ è½½éœ€è¦å‰¥ç¦»çš„æœåŠ¡å™¨è·¯å¾„å‰ç¼€"""
    if os.path.exists(PATH_MAP_CONFIG_PATH):
        with open(PATH_MAP_CONFIG_PATH, "r", encoding="utf-8") as f:
            return f.read().strip()
    return ""


def save_path_prefix(prefix):
    """ä¿å­˜è·¯å¾„å‰ç¼€é…ç½®"""
    try:
        with open(PATH_MAP_CONFIG_PATH, "w", encoding="utf-8") as f:
            f.write(prefix.strip())
        return True, "å·²ä¿å­˜"
    except Exception as e:
        return False, str(e)

# ==========================================
# 7. æ–‡ä»¶ IO ä¸è§£æ (ä¿ç•™å•ä¸€å®ç°)
# ==========================================
def load_file_content(filepath):
    """
    é€šç”¨æ–‡ä»¶è¯»å–å™¨ï¼šæ”¯æŒ .md, .txt, .log, .xlsx, .csv, .docx, .pdf
    """
    try:
        ext = os.path.splitext(filepath)[1].lower()

        # 1. Excel å¤„ç†
        if ext in [".xlsx", ".xls"]:
            return pd.read_excel(filepath).astype(str).agg(" ".join, axis=1).str.cat(sep="\n")

        # 2. CSV å¤„ç†
        if ext == ".csv":
            try:
                df = pd.read_csv(filepath, encoding="utf-8")
            except UnicodeDecodeError:
                df = pd.read_csv(filepath, encoding="gbk")
            return df.astype(str).agg(" ".join, axis=1).str.cat(sep="\n")

        # 3. Word å¤„ç†
        if ext == ".docx":
            if docx is None:
                return "âŒ é”™è¯¯: æœªå®‰è£… python-docx åº“"
            doc = docx.Document(filepath)
            return "\n".join([para.text for para in doc.paragraphs])

        # 4. PDF å¤„ç†
        if ext == ".pdf":
            if PdfReader is None:
                return "âŒ é”™è¯¯: æœªå®‰è£… pypdf åº“"
            reader = PdfReader(filepath)
            return "\n".join([page.extract_text() for page in reader.pages])

        # 5. çº¯æ–‡æœ¬å¤„ç†
        with open(filepath, "r", encoding="utf-8", errors="replace") as f:
            return f.read()
    except Exception as e:
        return f"âŒ æ–‡ä»¶è§£æå¤±è´¥ ({os.path.basename(filepath)}): {str(e)}"


def get_manuals_by_domain():
    tree = {}
    for d in DOMAINS:
        path = os.path.join(MANUAL_ROOT_DIR, d)
        if os.path.exists(path):
            tree[d] = sorted(
                [f for f in os.listdir(path) if f.lower().endswith((".md", ".pdf", ".docx", ".txt"))]
            )
    return tree


def save_uploaded_manuals(uploaded_files, domain):
    target_dir = os.path.join(MANUAL_ROOT_DIR, domain)
    os.makedirs(target_dir, exist_ok=True)
    for f in uploaded_files:
        with open(os.path.join(target_dir, f.name), "wb") as out_f:
            out_f.write(f.getbuffer())
    st.toast(f"âœ… {len(uploaded_files)} ä¸ªæ‰‹å†Œå·²ä¸Šä¼ è‡³ {domain}", icon="ğŸ“š")


def save_uploaded_logs(uploaded_files):
    os.makedirs(LOG_DIR, exist_ok=True)
    for f in uploaded_files:
        with open(os.path.join(LOG_DIR, f.name), "wb") as out_f:
            out_f.write(f.getbuffer())
    st.toast(f"âœ… {len(uploaded_files)} ä¸ªæ—¥å¿—å·²ä¸Šä¼ ", icon="ğŸªµ")


def delete_files(dir_path, filenames):
    for f in filenames:
        try:
            os.remove(os.path.join(dir_path, f))
        except Exception:
            pass
    st.toast(f"ğŸ—‘ï¸ å·²åˆ é™¤ {len(filenames)} ä¸ªæ–‡ä»¶", icon="ğŸ§¹")

# ==========================================
# 8. æ—¥å¿—å¤„ç†å·¥å…·
# ==========================================
def get_smart_snippet(content: str, head: int = 3000, tail: int = 3000) -> str:
    """æå–æ—¥å¿—å¤´å°¾çš„æ™ºèƒ½æ‘˜è¦ (åŒæ—¶é™ä½ Token æ¶ˆè€—)"""
    if not content:
        return ""
    char_limit = head + tail + 200
    if len(content) <= char_limit:
        return content

    head_part = content[:head]
    tail_part = content[-tail:] if tail > 0 else ""
    return f"{head_part}\n\n... (ä¸­é—´çœç•¥ {len(content) - head - tail} å­—ç¬¦) ...\n\n{tail_part}"


def filter_log_content(content: str, keywords: list, context_lines: int = 5) -> str:
    """
    å…³é”®æ—¥å¿—åˆç­›ç®—æ³• (ä¼˜åŒ–ç‰ˆ: åŸºäºç´¢å¼•é›†å»é‡):
    1. æ‰«ææ‰€æœ‰è¡Œï¼Œæ‰¾åˆ°åŒ…å« keywords çš„è¡Œã€‚
    2. é’ˆå¯¹æ¯ä¸€ä¸ªå‘½ä¸­è¡Œï¼Œå°†å…¶ å‰Nè¡Œ å’Œ åNè¡Œ çš„ç´¢å¼•åŠ å…¥é›†åˆã€‚
    3. å¯¹é›†åˆæ’åºï¼Œæå–å†…å®¹ã€‚
    4. å¦‚æœè¡Œå·ä¸è¿ç»­ï¼Œæ’å…¥åˆ†éš”ç¬¦ã€‚
    """
    if not content or not keywords:
        return content

    lines = content.splitlines()
    total_lines = len(lines)
    keep_indices = set()

    valid_keywords = [k.lower().strip() for k in keywords if k.strip()]
    if not valid_keywords:
        return content

    for i, line in enumerate(lines):
        line_lower = line.lower()
        if any(kw in line_lower for kw in valid_keywords):
            start = max(0, i - context_lines)
            end = min(total_lines, i + context_lines + 1)
            keep_indices.update(range(start, end))

    if not keep_indices:
        return (
            f"[System Filter]: åœ¨ {total_lines} è¡Œæ—¥å¿—ä¸­æœªæ‰¾åˆ°å…³é”®è¯ "
            f"{valid_keywords}ï¼Œè¯·æ£€æŸ¥å…³é”®è¯é…ç½®æˆ–å…³é—­åˆç­›ã€‚"
        )

    sorted_indices = sorted(list(keep_indices))
    result_lines = []
    last_idx = -1
    for idx in sorted_indices:
        if last_idx != -1 and idx > last_idx + 1:
            result_lines.append(f"\n... (è¿‡æ»¤æ‰ {idx - last_idx - 1} è¡Œæ— å…³æ—¥å¿—) ...\n")
        result_lines.append(f"Line {idx + 1}: {lines[idx]}")
        last_idx = idx

    return "\n".join(result_lines)

