"""
utils.py â€” LogPilot æ ¸å¿ƒå·¥å…·æ¨¡å— (Phase 1: ç”¨æˆ·éš”ç¦»ç‰ˆ)

å˜æ›´è®°å½•:
  - v3.1: ç”¨æˆ·å·¥ä½œç©ºé—´éš”ç¦»ã€æ–‡ä»¶å¤§å°é™åˆ¶ã€LLM ç¼“å­˜å±‚
"""
import hashlib
import json
import os
import shutil
import time

import pandas as pd
import streamlit as st

# ==========================================
# 0. ä¾èµ–åº“æ‡’åŠ è½½ (é˜²æ­¢æœªå®‰è£…åº“å¯¼è‡´é—ªé€€)
# ==========================================
try:
    import docx
except ImportError:
    docx = None

try:
    from pypdf import PdfReader
except ImportError:
    PdfReader = None

# ==========================================
# 1. å…¨å±€é…ç½®
# ==========================================
BASE_DIR = "analysis_workspace"
PROMPT_DIR = "prompts"
CONFIG_DIR = "user_configs"
CACHE_DIR = os.path.join(BASE_DIR, "cache")

# ---- å®‰å…¨é™åˆ¶ ----
MAX_UPLOAD_SIZE_MB = 50          # å•æ–‡ä»¶æœ€å¤§ 50MB
MAX_FILES_PER_USER = 100         # æ¯ç”¨æˆ·æœ€å¤š 100 ä¸ªæ–‡ä»¶
MAX_TOTAL_STORAGE_MB = 500       # æ¯ç”¨æˆ·æœ€å¤§ 500MB æ€»å­˜å‚¨

# ---- ä»£ç åº“ä¸è·¯å¾„æ˜ å°„é…ç½® ----
CODEBASE_CONFIG_PATH = os.path.join(CONFIG_DIR, "codebase_path.txt")
PATH_MAP_CONFIG_PATH = os.path.join(CONFIG_DIR, "path_mapping.txt")

# ---- é¢†åŸŸå®šä¹‰ ----
DOMAINS = ["BSP", "CLK", "SWITCH", "OTHER"]


# ==========================================
# 2. åˆå§‹èµ„äº§ (Prompt é»˜è®¤å€¼)
# ==========================================
INIT_SYSTEM_PROMPTS = {
    "BSP": """# Role
ä½ æ˜¯ä¸€ä¸ªåŸºç«™ BSP (Board Support Package) ç³»ç»Ÿçš„æ•…éšœåˆ¤å†³ä¸“å®¶ã€‚

# Context
è´Ÿè´£åˆ†æå¯åŠ¨æµç¨‹ã€é©±åŠ¨åŠ è½½ã€å†…å­˜ç®¡ç†åŠç¡¬ä»¶æŠ½è±¡å±‚æ•…éšœã€‚
çº¦æŸï¼š
1. ä¸¥æ ¼ä¾æ®æ‰‹å†Œåˆ¤æ®ï¼Œç¦æ­¢å‘æ•£ã€‚
2. åŒºåˆ†å¯åŠ¨é˜¶æ®µçš„ç¬æ€æŠ¥é”™ä¸æ°¸ä¹…å¤±è´¥ã€‚
3. è¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚""",
    "CLK": """# Role
ä½ æ˜¯ä¸€ä¸ªåŸºç«™æ—¶é’Ÿä¸åŒæ­¥å­ç³»ç»Ÿ (CLK) çš„æ•…éšœåˆ¤å†³ä¸“å®¶ã€‚

# Context
è´Ÿè´£ GNSSã€1588v2ã€PLL çŠ¶æ€åŠæ—¶é’Ÿæºåˆ‡æ¢åˆ†æã€‚
çº¦æŸï¼š
1. é‡ç‚¹å…³æ³¨ Lock/Unlock çŠ¶æ€åˆ‡æ¢åŠæ—¶åºã€‚
2. åŒºåˆ†éšæ€§æ•…éšœï¼ˆç›¸ä½åå·®ï¼‰ä¸æ˜¾æ€§æ•…éšœï¼ˆå‘Šè­¦ï¼‰ã€‚
3. è¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚""",
    "SWITCH": """# Role
ä½ æ˜¯ä¸€ä¸ªåŸºç«™äº¤æ¢ä¸ç½‘ç»œå­ç³»ç»Ÿ (SWITCH) çš„æ•…éšœåˆ¤å†³ä¸“å®¶ã€‚

# Context
è´Ÿè´£ VLANã€ç«¯å£çŠ¶æ€ã€é£æš´æŠ‘åˆ¶åŠæŠ¥æ–‡è½¬å‘åˆ†æã€‚
çº¦æŸï¼š
1. åŒºåˆ†ç‰©ç†é“¾è·¯æŠ–åŠ¨ä¸é€»è¾‘é…ç½®é”™è¯¯ã€‚
2. è¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚""",
    "OTHER": """# Role
ä½ æ˜¯ä¸€ä¸ªé€šç”¨çš„è‡ªåŠ¨åŒ–æ•…éšœåˆ¤å†³ä¸“å®¶ã€‚

è¯·ä¸¥æ ¼æ ¹æ®å‚è€ƒæ‰‹å†Œåˆ¤æ–­æ—¥å¿—ä¸­æ˜¯å¦å­˜åœ¨æ•…éšœã€‚è¾“å‡º JSON æ ¼å¼ã€‚""",
}

INIT_TASK_TEMPLATE = """# Task
è¯·åˆ†æä»¥ä¸‹æ—¥å¿—æ˜¯å¦æ»¡è¶³æ•…éšœæ‰‹å†Œä¸­çš„å®šä¹‰ã€‚

## Input Data
ã€å‚è€ƒæ‰‹å†Œã€‘:
{manual_content}

ã€ç³»ç»Ÿæ—¥å¿—ã€‘:
{log_content}

## Output Format (JSON Only)
{
    "is_fault": true,
    "confidence": 95,
    "title": "æ•…éšœåç§° (From Manual)",
    "reason": "ç®€è¦è¯æ®é“¾...",
    "fix": "ä¿®å¤å»ºè®®..."
}"""


# ==========================================
# 3. ç”¨æˆ·å·¥ä½œç©ºé—´ç®¡ç† (Phase 1 æ ¸å¿ƒ)
# ==========================================

def _sanitize_user_id(user_id: str) -> str:
    """å®‰å…¨åŒ–ç”¨æˆ· ID (é˜²ç›®å½•éå†)"""
    safe = "".join([c for c in str(user_id) if c.isalnum() or c in "_-"]) or "default"
    return safe[:64]  # é™åˆ¶é•¿åº¦


def get_user_workspace(user_id: str) -> dict:
    """
    è·å–ç”¨æˆ·ç‹¬ç«‹å·¥ä½œç©ºé—´è·¯å¾„ã€‚
    æ¯ä¸ªç”¨æˆ·æ‹¥æœ‰è‡ªå·±çš„ logs/ å’Œ manuals/ ç›®å½•ã€‚
    è¿”å› dict: {root, logs, manuals}
    """
    safe_id = _sanitize_user_id(user_id)
    root = os.path.join(BASE_DIR, "workspaces", safe_id)
    paths = {
        "root": root,
        "logs": os.path.join(root, "logs"),
        "manuals": root,  # manuals ä»æŒ‰ domain åˆ†ï¼Œåœ¨ root ä¸‹
    }
    return paths


def get_user_log_dir(user_id: str) -> str:
    return get_user_workspace(user_id)["logs"]


def get_user_manual_root(user_id: str) -> str:
    return os.path.join(get_user_workspace(user_id)["root"], "manuals")


# ---- å…¼å®¹æ—§ç‰ˆçš„å…¨å±€è·¯å¾„ (ä¾› Prompt/Config ä½¿ç”¨ï¼Œä¸éš”ç¦») ----
SHARED_MANUAL_ROOT_DIR = os.path.join(BASE_DIR, "shared_manuals")
LOG_DIR = os.path.join(BASE_DIR, "logs")            # ä¿ç•™å…¼å®¹
MANUAL_ROOT_DIR = os.path.join(BASE_DIR, "manuals")  # ä¿ç•™å…¼å®¹


def init_environment(user_id: str = "default"):
    """åˆå§‹åŒ–ç›®å½•å¹¶ç”Ÿæˆé»˜è®¤ Prompt æ–‡ä»¶"""
    # å…¨å±€ç›®å½•
    for d in [BASE_DIR, PROMPT_DIR, CONFIG_DIR, CACHE_DIR, SHARED_MANUAL_ROOT_DIR]:
        os.makedirs(d, exist_ok=True)

    # ç”¨æˆ·å·¥ä½œç©ºé—´
    ws = get_user_workspace(user_id)
    os.makedirs(ws["logs"], exist_ok=True)
    manual_root = get_user_manual_root(user_id)
    for domain in DOMAINS:
        os.makedirs(os.path.join(manual_root, domain), exist_ok=True)

    # å…±äº«æ‰‹å†Œç›®å½• (ç®¡ç†å‘˜ç»Ÿä¸€ç»´æŠ¤çš„æ ‡å‡†æ‰‹å†Œ)
    for domain in DOMAINS:
        os.makedirs(os.path.join(SHARED_MANUAL_ROOT_DIR, domain), exist_ok=True)

    # System Prompts
    for domain in DOMAINS:
        sys_path = os.path.join(PROMPT_DIR, f"system_{domain}.md")
        if not os.path.exists(sys_path):
            with open(sys_path, "w", encoding="utf-8") as f:
                f.write(INIT_SYSTEM_PROMPTS.get(domain, INIT_SYSTEM_PROMPTS["OTHER"]))

    # Task Template
    task_path = os.path.join(PROMPT_DIR, "task_default.md")
    if not os.path.exists(task_path):
        with open(task_path, "w", encoding="utf-8") as f:
            f.write(INIT_TASK_TEMPLATE)


def clear_user_workspace(user_id: str):
    """æ¸…ç©ºæŒ‡å®šç”¨æˆ·çš„å·¥ä½œæ•°æ®"""
    ws = get_user_workspace(user_id)
    if os.path.exists(ws["root"]):
        shutil.rmtree(ws["root"])
    init_environment(user_id)


def get_user_storage_usage(user_id: str) -> dict:
    """ç»Ÿè®¡ç”¨æˆ·å­˜å‚¨ä½¿ç”¨æƒ…å†µ"""
    ws = get_user_workspace(user_id)
    total_bytes = 0
    file_count = 0
    for dirpath, _, filenames in os.walk(ws["root"]):
        for f in filenames:
            fp = os.path.join(dirpath, f)
            total_bytes += os.path.getsize(fp)
            file_count += 1
    return {
        "total_mb": round(total_bytes / (1024 * 1024), 2),
        "file_count": file_count,
        "limit_mb": MAX_TOTAL_STORAGE_MB,
        "limit_files": MAX_FILES_PER_USER,
    }


# ==========================================
# 4. Prompt ç®¡ç†æ¥å£
# ==========================================
def get_prompt_path(layer, name):
    if layer == "SYSTEM":
        return os.path.join(PROMPT_DIR, f"system_{name}.md")
    if layer == "TASK":
        return os.path.join(PROMPT_DIR, f"task_{name}.md")
    return None


def load_prompt(layer, name):
    """è¯»å– Promptï¼Œä¼˜å…ˆè¯»æ–‡ä»¶"""
    path = get_prompt_path(layer, name)
    if path and os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            pass
    if layer == "SYSTEM":
        return INIT_SYSTEM_PROMPTS.get(name, INIT_SYSTEM_PROMPTS["OTHER"])
    return INIT_TASK_TEMPLATE


def save_prompt(layer, name, content):
    path = get_prompt_path(layer, name)
    if path:
        try:
            with open(path, "w", encoding="utf-8") as f:
                f.write(content)
            return True
        except Exception:
            pass
    return False


# ==========================================
# 5. ç”¨æˆ·é…ç½®ç®¡ç†
# ==========================================
def get_config_path(user_id):
    safe_id = _sanitize_user_id(user_id)
    return os.path.join(CONFIG_DIR, f"config_{safe_id}.json")


def load_user_config(user_id):
    path = get_config_path(user_id)
    default = {
        "base_url": "https://api.deepseek.com/v1",
        "model_name": "deepseek-chat",
        "api_key": "",
    }
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return {**default, **json.load(f)}
        except Exception:
            pass
    return default


def save_user_config(user_id, config_data):
    try:
        with open(get_config_path(user_id), "w", encoding="utf-8") as f:
            json.dump(config_data, f, indent=4)
        return True
    except Exception:
        return False


# ==========================================
# 6. æœ¬åœ°ä»£ç åº“ä¸è·¯å¾„æ˜ å°„é…ç½®
# ==========================================
def load_codebase_root():
    if os.path.exists(CODEBASE_CONFIG_PATH):
        with open(CODEBASE_CONFIG_PATH, "r", encoding="utf-8") as f:
            return f.read().strip()
    return ""


def save_codebase_root(path):
    try:
        os.makedirs(os.path.dirname(CODEBASE_CONFIG_PATH), exist_ok=True)
        with open(CODEBASE_CONFIG_PATH, "w", encoding="utf-8") as f:
            f.write(path.strip())
        return True, "å·²ä¿å­˜"
    except Exception as e:
        return False, str(e)


def load_path_prefix():
    if os.path.exists(PATH_MAP_CONFIG_PATH):
        with open(PATH_MAP_CONFIG_PATH, "r", encoding="utf-8") as f:
            return f.read().strip()
    return ""


def save_path_prefix(prefix):
    try:
        os.makedirs(os.path.dirname(PATH_MAP_CONFIG_PATH), exist_ok=True)
        with open(PATH_MAP_CONFIG_PATH, "w", encoding="utf-8") as f:
            f.write(prefix.strip())
        return True, "å·²ä¿å­˜"
    except Exception as e:
        return False, str(e)


# ==========================================
# 7. æ–‡ä»¶ IO ä¸è§£æ (å®‰å…¨å¢å¼ºç‰ˆ)
# ==========================================

def check_upload_allowed(user_id: str, file_size_bytes: int) -> tuple:
    """
    æ£€æŸ¥æ˜¯å¦å…è®¸ä¸Šä¼  (Phase 1 å®‰å…¨)
    Returns: (allowed: bool, reason: str)
    """
    # å•æ–‡ä»¶å¤§å°æ£€æŸ¥
    size_mb = file_size_bytes / (1024 * 1024)
    if size_mb > MAX_UPLOAD_SIZE_MB:
        return False, f"æ–‡ä»¶è¶…è¿‡ {MAX_UPLOAD_SIZE_MB}MB é™åˆ¶ (å½“å‰ {size_mb:.1f}MB)"

    # ç”¨æˆ·æ€»å­˜å‚¨æ£€æŸ¥
    usage = get_user_storage_usage(user_id)
    if usage["file_count"] >= MAX_FILES_PER_USER:
        return False, f"æ–‡ä»¶æ•°å·²è¾¾ä¸Šé™ ({MAX_FILES_PER_USER}ä¸ª)"
    if usage["total_mb"] + size_mb > MAX_TOTAL_STORAGE_MB:
        return False, f"å­˜å‚¨ç©ºé—´ä¸è¶³ (å·²ç”¨ {usage['total_mb']}MB / {MAX_TOTAL_STORAGE_MB}MB)"

    return True, "OK"


def load_file_content(filepath):
    """
    é€šç”¨æ–‡ä»¶è¯»å–å™¨ï¼šæ”¯æŒ .md, .txt, .log, .xlsx, .csv, .docx, .pdf
    """
    try:
        ext = os.path.splitext(filepath)[1].lower()

        if ext in [".xlsx", ".xls"]:
            return pd.read_excel(filepath).astype(str).agg(" ".join, axis=1).str.cat(sep="\n")

        if ext == ".csv":
            try:
                df = pd.read_csv(filepath, encoding="utf-8")
            except UnicodeDecodeError:
                df = pd.read_csv(filepath, encoding="gbk")
            return df.astype(str).agg(" ".join, axis=1).str.cat(sep="\n")

        if ext == ".docx":
            if docx is None:
                return "âŒ é”™è¯¯: æœªå®‰è£… python-docx åº“"
            doc = docx.Document(filepath)
            return "\n".join([para.text for para in doc.paragraphs])

        if ext == ".pdf":
            if PdfReader is None:
                return "âŒ é”™è¯¯: æœªå®‰è£… pypdf åº“"
            reader = PdfReader(filepath)
            return "\n".join([page.extract_text() or "" for page in reader.pages])

        with open(filepath, "r", encoding="utf-8", errors="replace") as f:
            return f.read()
    except Exception as e:
        return f"âŒ æ–‡ä»¶è§£æå¤±è´¥ ({os.path.basename(filepath)}): {str(e)}"


def get_manuals_by_domain(user_id: str = "default"):
    """è·å–ç”¨æˆ·æ‰‹å†Œåˆ—è¡¨ (åˆå¹¶: ç”¨æˆ·ç§æœ‰ + å…±äº«)"""
    tree = {}
    user_manual_root = get_user_manual_root(user_id)

    for d in DOMAINS:
        files = set()
        # ç”¨æˆ·ç§æœ‰æ‰‹å†Œ
        user_path = os.path.join(user_manual_root, d)
        if os.path.exists(user_path):
            files.update(
                f for f in os.listdir(user_path)
                if f.lower().endswith((".md", ".pdf", ".docx", ".txt"))
            )
        # å…±äº«æ‰‹å†Œ
        shared_path = os.path.join(SHARED_MANUAL_ROOT_DIR, d)
        if os.path.exists(shared_path):
            files.update(
                f for f in os.listdir(shared_path)
                if f.lower().endswith((".md", ".pdf", ".docx", ".txt"))
            )
        tree[d] = sorted(files)

    return tree


def resolve_manual_path(user_id: str, domain: str, filename: str) -> str:
    """è§£ææ‰‹å†Œæ–‡ä»¶çš„å®é™…è·¯å¾„ (ç”¨æˆ·ç§æœ‰ > å…±äº«)"""
    user_path = os.path.join(get_user_manual_root(user_id), domain, filename)
    if os.path.exists(user_path):
        return user_path
    shared_path = os.path.join(SHARED_MANUAL_ROOT_DIR, domain, filename)
    if os.path.exists(shared_path):
        return shared_path
    # å…¼å®¹æ—§è·¯å¾„
    old_path = os.path.join(MANUAL_ROOT_DIR, domain, filename)
    if os.path.exists(old_path):
        return old_path
    return user_path  # fallback


def save_uploaded_manuals(uploaded_files, domain, user_id="default"):
    target_dir = os.path.join(get_user_manual_root(user_id), domain)
    os.makedirs(target_dir, exist_ok=True)
    saved = 0
    for f in uploaded_files:
        allowed, reason = check_upload_allowed(user_id, f.size)
        if not allowed:
            st.error(f"âŒ {f.name}: {reason}")
            continue
        with open(os.path.join(target_dir, f.name), "wb") as out_f:
            out_f.write(f.getbuffer())
        saved += 1
    if saved > 0:
        st.toast(f"âœ… {saved} ä¸ªæ‰‹å†Œå·²ä¸Šä¼ è‡³ {domain}", icon="ğŸ“š")


def save_uploaded_logs(uploaded_files, user_id="default"):
    log_dir = get_user_log_dir(user_id)
    os.makedirs(log_dir, exist_ok=True)
    saved = 0
    for f in uploaded_files:
        allowed, reason = check_upload_allowed(user_id, f.size)
        if not allowed:
            st.error(f"âŒ {f.name}: {reason}")
            continue
        with open(os.path.join(log_dir, f.name), "wb") as out_f:
            out_f.write(f.getbuffer())
        saved += 1
    if saved > 0:
        st.toast(f"âœ… {saved} ä¸ªæ—¥å¿—å·²ä¸Šä¼ ", icon="ğŸªµ")


def delete_files(dir_path, filenames):
    for f in filenames:
        try:
            os.remove(os.path.join(dir_path, f))
        except Exception:
            pass
    st.toast(f"ğŸ—‘ï¸ å·²åˆ é™¤ {len(filenames)} ä¸ªæ–‡ä»¶", icon="ğŸ§¹")


# ==========================================
# 8. LLM ç»“æœç¼“å­˜ (Phase 1)
# ==========================================

def _make_cache_key(*args) -> str:
    """æ ¹æ®è¾“å…¥å†…å®¹ç”Ÿæˆç¼“å­˜ key"""
    content = "|".join(str(a)[:5000] for a in args)
    return hashlib.md5(content.encode("utf-8")).hexdigest()


def cache_get(namespace: str, *args) -> str | None:
    """è¯»å–ç¼“å­˜ï¼Œè¿”å› None è¡¨ç¤ºæœªå‘½ä¸­"""
    key = _make_cache_key(*args)
    cache_file = os.path.join(CACHE_DIR, namespace, f"{key}.json")
    if not os.path.exists(cache_file):
        return None
    try:
        with open(cache_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        # æ£€æŸ¥è¿‡æœŸ (é»˜è®¤ 24 å°æ—¶)
        if time.time() - data.get("ts", 0) > 86400:
            os.remove(cache_file)
            return None
        return data.get("value", "")
    except Exception:
        return None


def cache_set(namespace: str, value: str, *args):
    """å†™å…¥ç¼“å­˜"""
    key = _make_cache_key(*args)
    cache_dir = os.path.join(CACHE_DIR, namespace)
    os.makedirs(cache_dir, exist_ok=True)
    cache_file = os.path.join(cache_dir, f"{key}.json")
    try:
        with open(cache_file, "w", encoding="utf-8") as f:
            json.dump({"ts": time.time(), "value": value}, f, ensure_ascii=False)
    except Exception:
        pass


def cache_clear(namespace: str = ""):
    """æ¸…ç©ºç¼“å­˜"""
    target = os.path.join(CACHE_DIR, namespace) if namespace else CACHE_DIR
    if os.path.exists(target):
        shutil.rmtree(target)
        os.makedirs(target, exist_ok=True)


# ==========================================
# 9. æ—¥å¿—å¤„ç†å·¥å…·
# ==========================================
def get_smart_snippet(content: str, head: int = 3000, tail: int = 3000) -> str:
    """æå–æ—¥å¿—å¤´å°¾çš„æ™ºèƒ½æ‘˜è¦ (åŒæ—¶é™ä½ Token æ¶ˆè€—)"""
    if not content:
        return ""
    char_limit = head + tail + 200
    if len(content) <= char_limit:
        return content

    head_part = content[:head]
    tail_part = content[-tail:] if tail > 0 else ""
    return f"{head_part}\n\n... (ä¸­é—´çœç•¥ {len(content) - head - tail} å­—ç¬¦) ...\n\n{tail_part}"


def filter_log_content(content: str, keywords: list, context_lines: int = 5) -> str:
    """å…³é”®æ—¥å¿—åˆç­›ç®—æ³• (åŸºäºç´¢å¼•é›†å»é‡)"""
    if not content or not keywords:
        return content

    lines = content.splitlines()
    total_lines = len(lines)
    keep_indices = set()

    valid_keywords = [k.lower().strip() for k in keywords if k and k.strip()]
    if not valid_keywords:
        return content

    for i, line in enumerate(lines):
        line_lower = line.lower()
        if any(kw in line_lower for kw in valid_keywords):
            start = max(0, i - context_lines)
            end = min(total_lines, i + context_lines + 1)
            keep_indices.update(range(start, end))

    if not keep_indices:
        return (
            f"[System Filter]: åœ¨ {total_lines} è¡Œæ—¥å¿—ä¸­æœªæ‰¾åˆ°å…³é”®è¯ "
            f"{valid_keywords}ï¼Œè¯·æ£€æŸ¥å…³é”®è¯é…ç½®æˆ–å…³é—­åˆç­›ã€‚"
        )

    sorted_indices = sorted(list(keep_indices))
    result_lines = []
    last_idx = -1
    for idx in sorted_indices:
        if last_idx != -1 and idx > last_idx + 1:
            result_lines.append(f"\n... (è¿‡æ»¤æ‰ {idx - last_idx - 1} è¡Œæ— å…³æ—¥å¿—) ...\n")
        result_lines.append(f"Line {idx + 1}: {lines[idx]}")
        last_idx = idx

    return "\n".join(result_lines)
